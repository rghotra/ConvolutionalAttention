{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "automatic-harvard",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import requests as rq\n",
    "import os, io, h5py\n",
    "\n",
    "from tfomics import explain, evaluate\n",
    "\n",
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sufficient-ethnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = rq.get('https://www.dropbox.com/s/5iww0ootxkr6e21/synthetic_code_dataset.h5?raw=true')\n",
    "data.raise_for_status()\n",
    "\n",
    "with h5py.File(io.BytesIO(data.content), 'r') as dataset:\n",
    "    x_train = np.array(dataset['X_train']).astype(np.float32).transpose([0, 2, 1])\n",
    "    y_train = np.array(dataset['Y_train']).astype(np.float32)\n",
    "    x_valid = np.array(dataset['X_valid']).astype(np.float32).transpose([0, 2, 1])\n",
    "    y_valid = np.array(dataset['Y_valid']).astype(np.int32)\n",
    "    x_test = np.array(dataset['X_test']).astype(np.float32).transpose([0, 2, 1])\n",
    "    y_test = np.array(dataset['Y_test']).astype(np.int32)\n",
    "    model_test = np.array(dataset['model_test']).astype(np.float32).transpose([0, 2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "actual-olive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 16s 33ms/step - loss: 0.7196 - auroc: 0.7019 - aupr: 0.6890 - val_loss: 0.5462 - val_auroc: 0.8453 - val_aupr: 0.8419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x224cd507070>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.CNN_ATT(num_out=1)\n",
    "\n",
    "auroc = tf.keras.metrics.AUC(curve='ROC', name='auroc')\n",
    "aupr = tf.keras.metrics.AUC(curve='PR', name='aupr')\n",
    "model.compile(tf.keras.optimizers.Adam(0.0005), loss='binary_crossentropy', metrics=[auroc, aupr])\n",
    "\n",
    "lr_decay = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_aupr', factor=0.2, patient=5, verbose=1, min_lr=1e-7, mode='max')\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_aupr', patience=15, verbose=1, mode='max')\n",
    "model.fit(x_train, y_train, epochs=1, validation_data=(x_valid, y_valid), callbacks=[lr_decay, early_stop], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "african-student",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of test sequences to analyze (set this to 500 because expintgrad takes long)\n",
    "num_analyze = 500\n",
    "\n",
    "# get positive label sequences and sequence model\n",
    "pos_index = np.where(y_test[:,0] == 1)[0]   \n",
    "X = x_test[pos_index[:num_analyze]]\n",
    "X_model = model_test[pos_index[:num_analyze]]\n",
    "\n",
    "# instantiate explainer class\n",
    "explainer = explain.Explainer(model, class_index=0)\n",
    "\n",
    "# calculate attribution maps\n",
    "saliency_scores = explainer.saliency_maps(X)\n",
    "\n",
    "# reduce attribution maps to 1D scores\n",
    "sal_scores = explain.grad_times_input(X, saliency_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "powered-carrier",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saliency: 0.599+/-0.050\n"
     ]
    }
   ],
   "source": [
    "# compare distribution of attribution scores at positions with and without motifs\n",
    "\n",
    "threshold = 0.1\n",
    "saliency_roc, saliency_pr = evaluate.interpretability_performance(sal_scores, X_model, threshold)\n",
    "\n",
    "print(\"%s: %.3f+/-%.3f\"%('saliency', np.mean(saliency_roc), np.std(saliency_roc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "executive-surge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saliency: 0.055+/-0.117\n"
     ]
    }
   ],
   "source": [
    "# compare distribution of attribution scores at positions with and without motifs\n",
    "threshold = 0.1\n",
    "top_k = 10\n",
    "\n",
    "sal_signal, sal_noise_max, sal_noise_mean, sal_noise_topk = evaluate.signal_noise_stats(sal_scores, X_model, top_k, threshold)\n",
    "\n",
    "score = evaluate.calculate_snr(sal_signal, sal_noise_topk)\n",
    "\n",
    "print(\"%s: %.3f+/-%.3f\"%('saliency', np.mean(score), np.std(score)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
