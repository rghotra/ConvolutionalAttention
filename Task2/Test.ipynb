{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adopted-bearing",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import models\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bulgarian-metadata",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [1.]\n",
      " [0.]\n",
      " ...\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]]\n",
      "(14000, 200, 4)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_valid, y_valid, x_test, y_test, model_test = utils.get_synthetic_coded_dataset()\n",
    "\n",
    "print(y_train)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "partial-editing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "438/438 [==============================] - 17s 34ms/step - loss: 0.7242 - auroc: 0.7118 - aupr: 0.7034 - val_loss: 0.6002 - val_auroc: 0.8405 - val_aupr: 0.8335\n",
      "Epoch 2/2\n",
      "438/438 [==============================] - 13s 31ms/step - loss: 0.5074 - auroc: 0.8351 - aupr: 0.8195 - val_loss: 0.4740 - val_auroc: 0.8716 - val_aupr: 0.8681\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x208ef32d4c0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.CNN_ATT(num_out=1)\n",
    "\n",
    "auroc = tf.keras.metrics.AUC(curve='ROC', name='auroc')\n",
    "aupr = tf.keras.metrics.AUC(curve='PR', name='aupr')\n",
    "model.compile(tf.keras.optimizers.Adam(0.0005), loss='binary_crossentropy', metrics=[auroc, aupr])\n",
    "\n",
    "lr_decay = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_aupr', factor=0.2, patient=5, verbose=1, min_lr=1e-7, mode='max')\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_aupr', patience=15, verbose=1, mode='max')\n",
    "model.fit(x_train, y_train, epochs=2, validation_data=(x_valid, y_valid), callbacks=[lr_decay, early_stop], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "refined-ratio",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 500)\n"
     ]
    }
   ],
   "source": [
    "sal_roc, sal_pr, snr = utils.get_saliency_scores(model, x_test, y_test, model_test)\n",
    "print(np.array([sal_roc, sal_pr, snr]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "divine-possibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of test sequences to analyze (set this to 500 because expintgrad takes long)\n",
    "num_analyze = 500\n",
    "\n",
    "# get positive label sequences and sequence model\n",
    "pos_index = np.where(y_test[:,0] == 1)[0]   \n",
    "X = x_test[pos_index[:num_analyze]]\n",
    "X_model = model_test[pos_index[:num_analyze]]\n",
    "\n",
    "# instantiate explainer class\n",
    "explainer = explain.Explainer(model, class_index=0)\n",
    "\n",
    "# calculate attribution maps\n",
    "saliency_scores = explainer.saliency_maps(X)\n",
    "\n",
    "# reduce attribution maps to 1D scores\n",
    "sal_scores = explain.grad_times_input(X, saliency_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "careful-village",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saliency: 0.742+/-0.068\n"
     ]
    }
   ],
   "source": [
    "# compare distribution of attribution scores at positions with and without motifs\n",
    "\n",
    "threshold = 0.1\n",
    "saliency_roc, saliency_pr = evaluate.interpretability_performance(sal_scores, X_model, threshold)\n",
    "\n",
    "print(\"%s: %.3f+/-%.3f\"%('saliency', np.mean(saliency_roc), np.std(saliency_roc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "illegal-protocol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saliency: 0.917+/-0.402\n"
     ]
    }
   ],
   "source": [
    "# compare distribution of attribution scores at positions with and without motifs\n",
    "threshold = 0.1\n",
    "top_k = 10\n",
    "\n",
    "sal_signal, sal_noise_max, sal_noise_mean, sal_noise_topk = evaluate.signal_noise_stats(sal_scores, X_model, top_k, threshold)\n",
    "\n",
    "score = evaluate.calculate_snr(sal_signal, sal_noise_topk)\n",
    "\n",
    "print(\"%s: %.3f+/-%.3f\"%('saliency', np.mean(score), np.std(score)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
